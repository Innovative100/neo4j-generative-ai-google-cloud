{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3d39ab",
   "metadata": {
    "id": "3d3d39ab"
   },
   "source": [
    "# Ingestion\n",
    "This notebook parses data from XXX (need detail here) using Google Vertex AI Generative AI.  It then uses Generative AI to create Neo4j Cypher queries which write the data to a Neo4j database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a9328-f17d-48ae-b72e-c333fb867eb0",
   "metadata": {
    "id": "f17a9328-f17d-48ae-b72e-c333fb867eb0"
   },
   "source": [
    "## Setup\n",
    "This notebook should be run within Vertex AI Workbench.  Be sure to select \"single user\" when starting a managed notebook to run this.  Otherwise the auth won't allow access to the preview.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb2fda-70c8-4733-ac6f-2678e5cbff47",
   "metadata": {
    "id": "87eb2fda-70c8-4733-ac6f-2678e5cbff47"
   },
   "source": [
    "First we need to install the latest libraries for Generative AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43720d2e-05cd-49de-bbb9-15c0b10d768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user google-cloud-aiplatform --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f91036-7018-465f-b4af-8d5523e7ed3a",
   "metadata": {},
   "source": [
    "You will need to restart the kernel after the pip install completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad823ee-84ca-4de3-9b29-4b324ac5b9ae",
   "metadata": {
    "id": "4ad823ee-84ca-4de3-9b29-4b324ac5b9ae"
   },
   "outputs": [],
   "source": [
    "# Note, you will need to set your project_id\n",
    "project_id = 'neo4jbusinessdev'\n",
    "location = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c5a70c-aee1-462b-953a-4c87a524a111",
   "metadata": {
    "id": "42c5a70c-aee1-462b-953a-4c87a524a111"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "vertexai.init(project=project_id, location='us-central1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db2e49",
   "metadata": {
    "id": "48db2e49"
   },
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10113a08",
   "metadata": {
    "id": "10113a08"
   },
   "source": [
    "Now, let's define a function that can help clean the input data. The data refers to some figures like scanned images. We don't have them and so we will remove any such references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e430a536",
   "metadata": {
    "id": "e430a536"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "  clean = \"\\n\".join([row for row in text.split(\"\\n\")])\n",
    "  clean = re.sub(r'\\(fig[^)]*\\)', '', clean, flags=re.IGNORECASE)\n",
    "  return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43bb3c",
   "metadata": {
    "id": "4e43bb3c"
   },
   "source": [
    "## Prompt Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72960046",
   "metadata": {
    "id": "72960046"
   },
   "source": [
    "Let's take this case sheet and extract entities and relations using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ad98c",
   "metadata": {
    "id": "605ad98c"
   },
   "source": [
    "This is a helper function to talk to the LLM with our prompt and text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1148d87e",
   "metadata": {
    "id": "1148d87e"
   },
   "outputs": [],
   "source": [
    "def run_text_model(\n",
    "    project_id: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    "    max_decode_steps: int,\n",
    "    top_p: float,\n",
    "    top_k: int,\n",
    "    prompt: str,\n",
    "    location: str = \"us-central1\",\n",
    "    tuned_model_name: str = \"\",\n",
    "    ) :\n",
    "    \"\"\"Text Completion Use a Large Language Model.\"\"\"\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    model = TextGenerationModel.from_pretrained(model_name)\n",
    "    if tuned_model_name:\n",
    "      model = model.get_tuned_model(tuned_model_name)\n",
    "    response = model.predict(\n",
    "        prompt,\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_decode_steps,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781a12b",
   "metadata": {
    "id": "7781a12b"
   },
   "source": [
    "This is a simple prompt to start with. If the processing is very complex, you can also chain the prompts as and when required. I am going to use a single prompt here that will extract the text strictly as per the Entities and Relationships defined. This is a simplification. \n",
    "In the real scenario, especially with medical records, you have to leverage on Domain experts to define the Ontology systematically and capture the important information. You should also be mindful of following the relevant regulations around handling health records,\n",
    "\n",
    "Instead of one single large model, you can also consider chaining a number of smaller ones as per your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4f9a9",
   "metadata": {
    "id": "d2b4f9a9"
   },
   "source": [
    "Let's run our completion task with our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcbfd725",
   "metadata": {
    "id": "dcbfd725"
   },
   "outputs": [],
   "source": [
    "def extract_entities_relationships(prompt, tuned_model_name):\n",
    "    try:\n",
    "        res = run_text_model(project_id, \"text-bison@001\", 0, 1024, 0.8, 40, prompt, location, tuned_model_name)\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7921fa85",
   "metadata": {
    "id": "7921fa85"
   },
   "outputs": [],
   "source": [
    "person_prompt_tpl=\"\"\"From the Curriculum Vitae text for a job aspirant below, extract Entities strictly as instructed below\n",
    "1. First, look for this Entity type in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Person entity under `description` property\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,role:string,description:string //Person Node\n",
    "2. Description property should be the text summary and not more than 100 characters\n",
    "3. If you cannot find any information on the entities & relationships above, it is okay to return empty value. DO NOT create fictious data\n",
    "4. Do NOT create duplicate entities\n",
    "5. IMPORTANT: Restrict output within the token limit\n",
    "\n",
    "Example Output Format:\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Person\",\"id\":\"person1\",\"role\":\"Prompt Developer\",\"description\":\"Prompt Developer with more than 30 years of LLM experience\"}]\n",
    "}\n",
    "\n",
    "Question: Now, extract the Person for the text below -\n",
    "$ctext\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d903cb98-ce84-43bb-b860-71a394604a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "postion_prompt_tpl=\"\"\"From the Curriculum Vitae text for a job aspirant below, extract Entities & relationships strictly as instructed below\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Position',id:string,title:string,location:string,startDate:string,endDate:string,url:string //Position Node\n",
    "    label:'Company',id:string,name:string //Company Node\n",
    "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    position|AT_COMPANY|company\n",
    "3. If you cannot find any information on the entities & relationships above, it is okay to return empty value. DO NOT create fictious data\n",
    "4. Do NOT create duplicate entities\n",
    "5. IMPORTANT: Restrict output within the token limit\n",
    " \n",
    "Example Output Format:\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Position\",\"id\":\"position1\",\"title\":\"Software Engineer\",\"location\":\"Singapore\",startDate:\"2021-01-01\",endDate:\"present\"},\n",
    "    {\"label\":\"Position\",\"id\":\"position2\",\"title\":\"Senior Software Engineer\",\"location\":\"Mars\",startDate:\"2020-01-01\",endDate:\"2020-12-31\"},\n",
    "    {label:\"Company\",id:\"company1\",name:\"Neo4j Singapore Pte Ltd\"},\n",
    "    {\"label\":\"Company\",\"id\":\"company2\",\"name\":\"Neo4j Mars Inc\"}\n",
    "    ],\n",
    "    \"relationships\": [\"position1|AT_COMPANY|company1\",\"position2|AT_COMPANY|company2\"]\n",
    "}\n",
    "\n",
    "Question: Now, extract entities & relationships as mentioned above for the text below -\n",
    "$ctext\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ffdf7091-20ff-4537-9aa8-b96a9325b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_prompt_tpl=\"\"\"From the Curriculum Vitae text below, extract Entities strictly as instructed below\n",
    "1. First, look for Skill Entities in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below:\n",
    "    Entity Types:\n",
    "    label:'Skill',id:string,name:string,level:string //Skill Node\n",
    "2. DO NOT create fictious data\n",
    "3. Restrict to only 30 Skills //Figure out which skill is most used based on the experience and expertise\n",
    "\n",
    "Example Output Format:\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Skill\",\"id\":\"skill1\",\"name\":\"Neo4j\",\"level\":\"expert\"},{\"label\":\"Skill\",\"id\":\"skill2\",\"name\":\"Pytorch\",\"level\":\"expert\"}]\n",
    "}\n",
    "\n",
    "Question: Now, extract entities as mentioned above for the text below -\n",
    "$ctext\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e188d63a-1a13-4363-8917-1af3123cbda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_prompt_tpl=\"\"\"From the Curriculum Vitae text for a job aspirant below, extract Entities strictly as instructed below\n",
    "1. First, look for this Education entity type and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create other entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Education',id:string,degree:string,university:string,graduation_date:string,score:string,url:string,courses:string //Education Node\n",
    "2. If you cannot find any information on the entities & relationships above, it is okay to return empty value. DO NOT create fictious data\n",
    "3. Do NOT create duplicate entities\n",
    "4. No Skill Entity in the output\n",
    "\n",
    "Example Output Format:\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Education\",\"id\":\"education1\",\"degree\":\"Bachelor of Science\",\"graduationDate\":\"May 2022\",\"score\":\"5.0\"}]\n",
    "}\n",
    "\n",
    "Question: Now, extract entities as mentioned above for the text below -\n",
    "$ctext\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6JKeHYgb4op-",
   "metadata": {
    "id": "6JKeHYgb4op-"
   },
   "outputs": [],
   "source": [
    "sample_que = \"\"\"Lead Software Developer Lead Software <span class=\"hl\">Developer</span> Lead Software Developer - O'Connor and Associates Montgomery, TX Work Experience Lead Software Developer O'Connor and Associates - Houston, TX October 2016 to Present � Manage acquisition and loading of County Appraisal District (CAD) data for 115+ counties in Texas.� � Manage offshore team of developers for custom built property tax applications.� � Create custom utility applications in Delphi to support business activities.� � Member of company leadership team and Center of Excellence initiative.� � Updated legacy Excel macros to work with Excel 2010+.� � Provide support for several applications in MS Access and C#.� � Create SQL queries for reports for management.� � Setup custom Zoho CRM fields and import sales leads.� � Mentor Junior IT staff� � Design marketing banners and flyers. Data Administrator/Software Developer Property Data Cloud - Houston, TX January 2013 to July 2019 � Manage acquisition, loading, and normalization of CAD data.� � Manage data for over 100 Texas County Appraisal Districts.� � Extract sales, income, cost data from PDF for loading into SQL.� � Database and software support for PDC clients.� � This is a contract, part-time position. Software Developer PCCA / PK Software - Houston, TX January 2013 to September 2016 � Develop Pharmacy software in Delphi 6 and Delphi XE2 with Firebird and SQL Server database backend.� � Convert applications from Delphi 6 to Delphi XE2.� � Took ownership of company website, responsible for updates and changes.� � Main point of contact for customers with database performance issues. Configure customer Firebird installations for maximum performance.� � Main developer and point of contact for integration with TeleManager IVR.� � Manage Axosoft OnTime server.� � Create installation packages with InstallShield.� � Create icons and images for use in PK Software applications and PK Software website. IT Director Commercial Tax Network - Houston, TX April 2006 to December 2012 � Managed computer operations (database, networking, programming, support). As of July, 2009, manage one network/desktop support technician.� � Manage server infrastructure on VMWare ESXi 4.� � Create new internal applications using Delphi 2006 and SQL Server 2008. Applications interface with SQL Server and use a variety of technologies including SMTP, downloading through HTTP, MS Word mail merge, exporting data to MS Excel spreadsheets.� � Completely recoded and redesigned legacy MS Access data system application to Delphi 2006/SQL Server.� � Integrated SmartSearch document management system with custom Delphi/SQL 2008 applications.� � Work closely with company executives to implement and improve business processes.� � Manage the acquisition and loading and normalization of CAD data.� � DBA for SQL Server 2008 database. Manage indexes, stored procedures and triggers to support database stability and performance. Perform ad-hoc queries to support business needs. Import and update data through the use of DTS and SQL queries.� � Query Appraisal District data to provide targeted mailing lists for marketing.� � Administer company email on Exchange Server 2010.� � Interact with vendors (phone, internet, LAN, etc.) to assure quality, reliable services.� � Managed moving of T1, phone, and LAN services to new building with minimal downtime. Provide technical support HP - Houston, TX 2007 to 2010 for 25 - 30 employees in two offices (Houston, TX and Atlanta, GA). Support Windows 7/Windows XP Pro environment as well as MS Office 2003/2007/2010, Quickbooks, IE, Firefox, ArcGIS, HP, Lexmark, and Dell printers and custom designed software.� � Build custom PCs, upgrade and repair PCs.� � Maintain company website (commercialtax.com).� � Work with ArcGIS software to provide GIS mapping solutions. Technical Consultant Kim Lighting - Industry, CA November 2005 to January 2007 � Provide technical consulting for company's website and software applications.� � Provide javascript programming for company's pdf specification sheets. Web Developer/Administrator Danzco Dance Academy - Montgomery, TX August 2004 to December 2006 � Designed and developed www.danzcodanceacademy.com. Site uses object oriented PHP/mySQL to display dynamic content.� � Created custom bulletin board system with PHP/mySQL.� � Converted text file based chat script to use PHP/mySQL.� � Tested new scripts on Apache Web Server. Web Developer/Administrator MCYBA - Magnolia, TX September 2002 to December 2006 Designed and developed website for local youth baseball organization. Site featured dynamic content, such as team schedules, game results, and team articles. Site uses object oriented PHP scripting and mySQL database. Web Developer/Administrator Hit-Away Indoor Sports Facility - Tomball, TX February 2000 to December 2006 � Designed and developed www.hit-away.com. Site used PHP/mySQL to provide dynamic content.� � Provided technical support and consulting services. Software Developer II Desktop Assistance, L.P - Houston, TX October 1999 to November 2005 � Design and develop software applications using Borland Delphi 4, 5, 6 and 7 and several database systems (e.g. Interbase, MS Access, Dbase).� � Designed and developed several key applications in our custom information management system. The first was a messaging and workflow application, similar to MS Outlook. The second was a viewer for viewing our custom documents.� � Developed and maintained client website, www.kimlighting.com.� � Solely responsible for updating Kim Lighting specification sheets for use in their Specification CD software and their website.� � Modified Kim Lighting's PDF product specification sheets to allow for user interaction using JavaScript.� � Handled all technical support for Kim Lighting software and website.� � Helped develop in-house application to automatically build all pages for the Kim Lighting website.� � Developed several small applications that interacted with XML.� � Handled all technical support for our software for the first 1-� years of my employment at Desktop Assistance.� � Developed in-house Development Guidelines and Standards documentation for our current project. Programmer I/II TDCJ - Huntsville, TX 1998 to 1999 � Designed and developed custom software applications for use in the Human Resources headquarters using Borland Delphi 3 and 4, and IBM DB2 database system.� � Communicated with analysts and end-users in several departments to acquire specifications for new applications.� � Helped develop the IBM DB2 database that would be the heart of all Human Resource applications.� � Worked with System Support representatives to help solve user computer problems. (e.g. Software problems, connecting to the database, etc.)� � Was the IS/IT liaison to the web site development group, which consisted of members of each HR department. Internet and Technologies Programmer Tejas Instruments, Inc - The Woodlands, TX 1998 to 1998 � Developed an inventory entry database system using Microsoft Access 97.� � Assisted in the development of Tejas Instruments Oil and Gas Flow Products Inc. and TexaCan Surplus Pipeline Equipment Inc. web sites and Internet endeavors.� � Assisted office staff in use of common software (i.e. Word, Excel) Jr. Programmer Vintage Sports Plaques - Conroe, TX 1997 to 1997 � Developed in-house reporting applications using FoxPro and Dbase.� � Assisted office staff in use of common software (i.e. Word, Excel). Programmer/Analyst Sterling Trust Company - Waco, TX 1995 to 1997 � Developed VAX/VMS data entry and reporting applications using COBOL and DB2 database system.� � Consulted with end-users to obtain specifications for new or existing applications.� � Provided users with a wide range of technical support, from 3rd party software applications, to in-house applications, to basic computer tasks. Education AAS degree in Computer Science Technology in Computer Science Technology Texas State Technical College - Waco, TX 1995 to 1997 AAS degree in design Texas State Technical College Skills MYSQL, Javascript, PHP, CSS, HTML 5, SQL (10+ years), Delphi (10+ years), Wordpress (4 years), Photoshop (8 years), Microsoft Office (10+ years)\"\"\"\n",
    "\n",
    "from string import Template\n",
    "prompts = [person_prompt_tpl, postion_prompt_tpl, skill_prompt_tpl, edu_prompt_tpl]\n",
    "import json\n",
    "results = {\"entities\": [], \"relationships\": []}\n",
    "for p in prompts:\n",
    "    _prompt = Template(p).substitute(ctext=clean_text(sample_que))\n",
    "    _extraction = extract_entities_relationships(_prompt, '') #entity_extraction_tuned_model)\n",
    "    if 'Answer:\\n' in _extraction:\n",
    "        _extraction = _extraction.split('Answer:\\n ')[1]\n",
    "    _extraction = json.loads(_extraction.replace(\"\\'\", \"'\"))\n",
    "    results[\"entities\"].extend(_extraction[\"entities\"])\n",
    "    if \"relationships\" in _extraction:\n",
    "        results[\"relationships\"].extend(_extraction[\"relationships\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b37bf-f355-4571-95e1-f307a65483b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_id = results[\"entities\"][0][\"id\"]\n",
    "for e in results[\"entities\"][1:]:\n",
    "    if e['label'] == 'Position':\n",
    "        results[\"relationships\"].append(f\"{person_id}|HAS_POSITION|{e['id']}\")\n",
    "    if e['label'] == 'Skill':\n",
    "        results[\"relationships\"].append(f\"{person_id}|HAS_SKILL|{e['id']}\")\n",
    "    if e['label'] == 'Education':\n",
    "        results[\"relationships\"].append(f\"{person_id}|HAS_EDUCATION|{e['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb2a60",
   "metadata": {
    "id": "8feb2a60"
   },
   "source": [
    "## Neo4j Cypher Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96efc5",
   "metadata": {
    "id": "0b96efc5"
   },
   "source": [
    "The entities and relationships we got from the LLM have to be transformed to Cypher so we can write them into Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "084047d0",
   "metadata": {
    "id": "084047d0"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_prop_str(prop_dict, _id):\n",
    "    s = []\n",
    "    for key, val in prop_dict.items():\n",
    "      if key != 'label' and key != 'id':\n",
    "         s.append(_id+\".\"+key+' = \"'+str(val).replace('\\\"', '\"').replace('\"', '\\\"')+'\"') \n",
    "    return ' ON CREATE SET ' + ','.join(s)\n",
    "\n",
    "def get_cypher_compliant_var(_id):\n",
    "    return \"_\"+ re.sub(r'[\\W_]', '', _id)\n",
    "\n",
    "def generate_cypher(in_json):\n",
    "    e_map = {}\n",
    "    e_stmt = []\n",
    "    r_stmt = []\n",
    "    e_stmt_tpl = Template(\"($id:$label{id:'$key'})\")\n",
    "    r_stmt_tpl = Template(\"\"\"\n",
    "      MATCH $src\n",
    "      MATCH $tgt\n",
    "      MERGE ($src_id)-[:$rel]->($tgt_id)\n",
    "    \"\"\")\n",
    "    for obj in in_json:\n",
    "      for j in obj['entities']:\n",
    "          props = ''\n",
    "          label = j['label']\n",
    "          id = j['id']\n",
    "          if label == 'Person':\n",
    "                id = 'c'+str(time.time_ns())\n",
    "          elif label == 'Position':\n",
    "                id = 'p'+str(time.time_ns())\n",
    "          varname = get_cypher_compliant_var(j['id'])\n",
    "          stmt = e_stmt_tpl.substitute(id=varname, label=label, key=id)\n",
    "          e_map[varname] = stmt\n",
    "          e_stmt.append('MERGE '+ stmt + get_prop_str(j, varname))\n",
    "\n",
    "      for st in obj['relationships']:\n",
    "          rels = st.split(\"|\")\n",
    "          src_id = get_cypher_compliant_var(rels[0].strip())\n",
    "          rel = rels[1].strip()\n",
    "          tgt_id = get_cypher_compliant_var(rels[2].strip())\n",
    "          stmt = r_stmt_tpl.substitute(\n",
    "              src_id=src_id, tgt_id=tgt_id, src=e_map[src_id], tgt=e_map[tgt_id], rel=rel)\n",
    "          \n",
    "          r_stmt.append(stmt)\n",
    "\n",
    "    return e_stmt, r_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ec143b14",
   "metadata": {
    "id": "ec143b14",
    "outputId": "6d2c5379-3ed9-4be4-ff94-433c21fd1275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MERGE (_person1:Person{id:\\'c1685086177338707569\\'}) ON CREATE SET _person1.role = \"Lead Software Developer\",_person1.description = \"Lead Software Developer with over 20 years of experience in software development, database administration, and web development. Expertise in Delphi, PHP, CSS, HTML 5, SQL, Javascript, Wordpress, Photoshop, and Microsoft Office.\"', 'MERGE (_position1:Position{id:\\'p1685086177338741365\\'}) ON CREATE SET _position1.title = \"Lead Software Developer\",_position1.location = \"Houston, TX\",_position1.startDate = \"October 2016\",_position1.endDate = \"Present\"', 'MERGE (_company1:Company{id:\\'company1\\'}) ON CREATE SET _company1.name = \"O\\'Connor and Associates\"', 'MERGE (_position2:Position{id:\\'p1685086177338764631\\'}) ON CREATE SET _position2.title = \"Data Administrator/Software Developer\",_position2.location = \"Houston, TX\",_position2.startDate = \"January 2013\",_position2.endDate = \"July 2019\"', 'MERGE (_company2:Company{id:\\'company2\\'}) ON CREATE SET _company2.name = \"Property Data Cloud\"', 'MERGE (_position3:Position{id:\\'p1685086177338782213\\'}) ON CREATE SET _position3.title = \"Software Developer\",_position3.location = \"Houston, TX\",_position3.startDate = \"January 2013\",_position3.endDate = \"September 2016\"', 'MERGE (_company3:Company{id:\\'company3\\'}) ON CREATE SET _company3.name = \"PCCA / PK Software\"', 'MERGE (_position4:Position{id:\\'p1685086177338852705\\'}) ON CREATE SET _position4.title = \"IT Director\",_position4.location = \"Houston, TX\",_position4.startDate = \"April 2006\",_position4.endDate = \"December 2012\"', 'MERGE (_company4:Company{id:\\'company4\\'}) ON CREATE SET _company4.name = \"Commercial Tax Network\"', 'MERGE (_position5:Position{id:\\'p1685086177338869059\\'}) ON CREATE SET _position5.title = \"Technical Consultant\",_position5.location = \"Industry, CA\",_position5.startDate = \"November 2005\",_position5.endDate = \"January 2007\"', 'MERGE (_company5:Company{id:\\'company5\\'}) ON CREATE SET _company5.name = \"Kim Lighting\"', 'MERGE (_position6:Position{id:\\'p1685086177338884336\\'}) ON CREATE SET _position6.title = \"Web Developer/Administrator\",_position6.location = \"Montgomery, TX\",_position6.startDate = \"August 2004\",_position6.endDate = \"December 2006\"', 'MERGE (_company6:Company{id:\\'company6\\'}) ON CREATE SET _company6.name = \"Danzco Dance Academy\"', 'MERGE (_position7:Position{id:\\'p1685086177338905714\\'}) ON CREATE SET _position7.title = \"Web Developer/Administrator\",_position7.location = \"Magnolia, TX\",_position7.startDate = \"September 2002\",_position7.endDate = \"December 2006\"', 'MERGE (_company7:Company{id:\\'company7\\'}) ON CREATE SET _company7.name = \"MCYBA\"', 'MERGE (_position8:Position{id:\\'p1685086177338920996\\'}) ON CREATE SET _position8.title = \"Web Developer/Administrator\",_position8.location = \"Tomball, TX\",_position8.startDate = \"February 2000\",_position8.endDate = \"December 2006\"', 'MERGE (_company8:Company{id:\\'company8\\'}) ON CREATE SET _company8.name = \"Hit-Away Indoor Sports Facility\"', 'MERGE (_position9:Position{id:\\'p1685086177338936860\\'}) ON CREATE SET _position9.title = \"Software Developer II\",_position9.location = \"Houston, TX\",_position9.startDate = \"October 1999\",_position9.endDate = \"November 2005\"', 'MERGE (_company9:Company{id:\\'company9\\'}) ON CREATE SET _company9.name = \"Desktop Assistance, L.P\"', 'MERGE (_position10:Position{id:\\'p1685086177338951732\\'}) ON CREATE SET _position10.title = \"Programmer I/II\",_position10.location = \"Huntsville, TX\",_position10.startDate = \"1998\",_position10.endDate = \"1999\"', 'MERGE (_company10:Company{id:\\'company10\\'}) ON CREATE SET _company10.name = \"TDCJ\"', 'MERGE (_position11:Position{id:\\'p1685086177338966173\\'}) ON CREATE SET _position11.title = \"Internet and Technologies Programmer\",_position11.location = \"The Woodlands, TX\",_position11.startDate = \"1998\",_position11.endDate = \"1998\"', 'MERGE (_company11:Company{id:\\'company11\\'}) ON CREATE SET _company11.name = \"Tejas Instruments, Inc\"', 'MERGE (_position12:Position{id:\\'p1685086177338982003\\'}) ON CREATE SET _position12.title = \"Jr. Programmer\",_position12.location = \"Conroe, TX\",_position12.startDate = \"1997\",_position12.endDate = \"1997\"', 'MERGE (_company12:Company{id:\\'company12\\'}) ON CREATE SET _company12.name = \"Vintage Sports Plaques\"', 'MERGE (_position13:Position{id:\\'p1685086177338995804\\'}) ON CREATE SET _position13.title = \"Programmer/Analyst\",_position13.location = \"Waco, TX\",_position13.startDate = \"1995\",_position13.endDate = \"1997\"', 'MERGE (_company13:Company{id:\\'company13\\'}) ON CREATE SET _company13.name = \"Sterling Trust Company\"', 'MERGE (_skill1:Skill{id:\\'skill1\\'}) ON CREATE SET _skill1.name = \"SQL\",_skill1.level = \"expert\"', 'MERGE (_skill2:Skill{id:\\'skill2\\'}) ON CREATE SET _skill2.name = \"Delphi\",_skill2.level = \"expert\"', 'MERGE (_skill3:Skill{id:\\'skill3\\'}) ON CREATE SET _skill3.name = \"PHP\",_skill3.level = \"expert\"', 'MERGE (_skill4:Skill{id:\\'skill4\\'}) ON CREATE SET _skill4.name = \"Javascript\",_skill4.level = \"expert\"', 'MERGE (_skill5:Skill{id:\\'skill5\\'}) ON CREATE SET _skill5.name = \"CSS\",_skill5.level = \"expert\"', 'MERGE (_skill6:Skill{id:\\'skill6\\'}) ON CREATE SET _skill6.name = \"HTML 5\",_skill6.level = \"expert\"', 'MERGE (_skill7:Skill{id:\\'skill7\\'}) ON CREATE SET _skill7.name = \"Wordpress\",_skill7.level = \"expert\"', 'MERGE (_skill8:Skill{id:\\'skill8\\'}) ON CREATE SET _skill8.name = \"Photoshop\",_skill8.level = \"expert\"', 'MERGE (_skill9:Skill{id:\\'skill9\\'}) ON CREATE SET _skill9.name = \"Microsoft Office\",_skill9.level = \"expert\"', 'MERGE (_skill10:Skill{id:\\'skill10\\'}) ON CREATE SET _skill10.name = \"MS Access\",_skill10.level = \"expert\"', 'MERGE (_skill11:Skill{id:\\'skill11\\'}) ON CREATE SET _skill11.name = \"MS Excel\",_skill11.level = \"expert\"', 'MERGE (_skill12:Skill{id:\\'skill12\\'}) ON CREATE SET _skill12.name = \"MS Word\",_skill12.level = \"expert\"', 'MERGE (_skill13:Skill{id:\\'skill13\\'}) ON CREATE SET _skill13.name = \"MS Outlook\",_skill13.level = \"expert\"', 'MERGE (_skill14:Skill{id:\\'skill14\\'}) ON CREATE SET _skill14.name = \"MS PowerPoint\",_skill14.level = \"expert\"', 'MERGE (_skill15:Skill{id:\\'skill15\\'}) ON CREATE SET _skill15.name = \"MS Visio\",_skill15.level = \"expert\"', 'MERGE (_skill16:Skill{id:\\'skill16\\'}) ON CREATE SET _skill16.name = \"MS Project\",_skill16.level = \"expert\"', 'MERGE (_skill17:Skill{id:\\'skill17\\'}) ON CREATE SET _skill17.name = \"MS Publisher\",_skill17.level = \"expert\"', 'MERGE (_skill18:Skill{id:\\'skill18\\'}) ON CREATE SET _skill18.name = \"MS FrontPage\",_skill18.level = \"expert\"', 'MERGE (_skill19:Skill{id:\\'skill19\\'}) ON CREATE SET _skill19.name = \"MS Access 2003\",_skill19.level = \"expert\"', 'MERGE (_skill20:Skill{id:\\'skill20\\'}) ON CREATE SET _skill20.name = \"MS Excel 2003\",_skill20.level = \"expert\"', 'MERGE (_skill21:Skill{id:\\'skill21\\'}) ON CREATE SET _skill21.name = \"MS Word 2003\",_skill21.level = \"expert\"', 'MERGE (_skill22:Skill{id:\\'skill22\\'}) ON CREATE SET _skill22.name = \"MS Outlook 2003\",_skill22.level = \"expert\"', 'MERGE (_skill23:Skill{id:\\'skill23\\'}) ON CREATE SET _skill23.name = \"MS PowerPoint 2003\",_skill23.level = \"expert\"', 'MERGE (_skill24:Skill{id:\\'skill24\\'}) ON CREATE SET _skill24.name = \"MS Visio 2003\",_skill24.level = \"expert\"', 'MERGE (_skill25:Skill{id:\\'skill25\\'}) ON CREATE SET _skill25.name = \"MS Project 2003\",_skill25.level = \"expert\"', 'MERGE (_skill26:Skill{id:\\'skill26\\'}) ON CREATE SET _skill26.name = \"MS Publisher 2003\",_skill26.level = \"expert\"', 'MERGE (_skill27:Skill{id:\\'skill27\\'}) ON CREATE SET _skill27.name = \"MS FrontPage 2003\",_skill27.level = \"expert\"', 'MERGE (_skill28:Skill{id:\\'skill28\\'}) ON CREATE SET _skill28.name = \"MS Access 2007\",_skill28.level = \"expert\"', 'MERGE (_skill29:Skill{id:\\'skill29\\'}) ON CREATE SET _skill29.name = \"MS Excel 2007\",_skill29.level = \"expert\"', 'MERGE (_skill30:Skill{id:\\'skill30\\'}) ON CREATE SET _skill30.name = \"MS Word 2007\",_skill30.level = \"expert\"', 'MERGE (_education1:Education{id:\\'education1\\'}) ON CREATE SET _education1.degree = \"AAS degree in Computer Science Technology\",_education1.university = \"Texas State Technical College\",_education1.graduation_date = \"1997\"', 'MERGE (_education2:Education{id:\\'education2\\'}) ON CREATE SET _education2.degree = \"AAS degree in design\",_education2.university = \"Texas State Technical College\",_education2.graduation_date = \"1997\"'] [\"\\n      MATCH (_position1:Position{id:'p1685086177338741365'})\\n      MATCH (_company1:Company{id:'company1'})\\n      MERGE (_position1)-[:AT_COMPANY]->(_company1)\\n    \", \"\\n      MATCH (_position2:Position{id:'p1685086177338764631'})\\n      MATCH (_company2:Company{id:'company2'})\\n      MERGE (_position2)-[:AT_COMPANY]->(_company2)\\n    \", \"\\n      MATCH (_position3:Position{id:'p1685086177338782213'})\\n      MATCH (_company3:Company{id:'company3'})\\n      MERGE (_position3)-[:AT_COMPANY]->(_company3)\\n    \", \"\\n      MATCH (_position4:Position{id:'p1685086177338852705'})\\n      MATCH (_company4:Company{id:'company4'})\\n      MERGE (_position4)-[:AT_COMPANY]->(_company4)\\n    \", \"\\n      MATCH (_position5:Position{id:'p1685086177338869059'})\\n      MATCH (_company5:Company{id:'company5'})\\n      MERGE (_position5)-[:AT_COMPANY]->(_company5)\\n    \", \"\\n      MATCH (_position6:Position{id:'p1685086177338884336'})\\n      MATCH (_company6:Company{id:'company6'})\\n      MERGE (_position6)-[:AT_COMPANY]->(_company6)\\n    \", \"\\n      MATCH (_position7:Position{id:'p1685086177338905714'})\\n      MATCH (_company7:Company{id:'company7'})\\n      MERGE (_position7)-[:AT_COMPANY]->(_company7)\\n    \", \"\\n      MATCH (_position8:Position{id:'p1685086177338920996'})\\n      MATCH (_company8:Company{id:'company8'})\\n      MERGE (_position8)-[:AT_COMPANY]->(_company8)\\n    \", \"\\n      MATCH (_position9:Position{id:'p1685086177338936860'})\\n      MATCH (_company9:Company{id:'company9'})\\n      MERGE (_position9)-[:AT_COMPANY]->(_company9)\\n    \", \"\\n      MATCH (_position10:Position{id:'p1685086177338951732'})\\n      MATCH (_company10:Company{id:'company10'})\\n      MERGE (_position10)-[:AT_COMPANY]->(_company10)\\n    \", \"\\n      MATCH (_position11:Position{id:'p1685086177338966173'})\\n      MATCH (_company11:Company{id:'company11'})\\n      MERGE (_position11)-[:AT_COMPANY]->(_company11)\\n    \", \"\\n      MATCH (_position12:Position{id:'p1685086177338982003'})\\n      MATCH (_company12:Company{id:'company12'})\\n      MERGE (_position12)-[:AT_COMPANY]->(_company12)\\n    \", \"\\n      MATCH (_position13:Position{id:'p1685086177338995804'})\\n      MATCH (_company13:Company{id:'company13'})\\n      MERGE (_position13)-[:AT_COMPANY]->(_company13)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position1:Position{id:'p1685086177338741365'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position1)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position2:Position{id:'p1685086177338764631'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position2)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position3:Position{id:'p1685086177338782213'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position3)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position4:Position{id:'p1685086177338852705'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position4)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position5:Position{id:'p1685086177338869059'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position5)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position6:Position{id:'p1685086177338884336'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position6)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position7:Position{id:'p1685086177338905714'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position7)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position8:Position{id:'p1685086177338920996'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position8)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position9:Position{id:'p1685086177338936860'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position9)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position10:Position{id:'p1685086177338951732'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position10)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position11:Position{id:'p1685086177338966173'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position11)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position12:Position{id:'p1685086177338982003'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position12)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_position13:Position{id:'p1685086177338995804'})\\n      MERGE (_person1)-[:HAS_POSITION]->(_position13)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill1:Skill{id:'skill1'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill1)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill2:Skill{id:'skill2'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill2)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill3:Skill{id:'skill3'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill3)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill4:Skill{id:'skill4'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill4)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill5:Skill{id:'skill5'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill5)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill6:Skill{id:'skill6'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill6)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill7:Skill{id:'skill7'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill7)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill8:Skill{id:'skill8'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill8)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill9:Skill{id:'skill9'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill9)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill10:Skill{id:'skill10'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill10)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill11:Skill{id:'skill11'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill11)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill12:Skill{id:'skill12'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill12)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill13:Skill{id:'skill13'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill13)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill14:Skill{id:'skill14'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill14)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill15:Skill{id:'skill15'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill15)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill16:Skill{id:'skill16'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill16)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill17:Skill{id:'skill17'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill17)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill18:Skill{id:'skill18'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill18)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill19:Skill{id:'skill19'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill19)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill20:Skill{id:'skill20'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill20)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill21:Skill{id:'skill21'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill21)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill22:Skill{id:'skill22'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill22)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill23:Skill{id:'skill23'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill23)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill24:Skill{id:'skill24'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill24)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill25:Skill{id:'skill25'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill25)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill26:Skill{id:'skill26'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill26)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill27:Skill{id:'skill27'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill27)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill28:Skill{id:'skill28'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill28)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill29:Skill{id:'skill29'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill29)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_skill30:Skill{id:'skill30'})\\n      MERGE (_person1)-[:HAS_SKILL]->(_skill30)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_education1:Education{id:'education1'})\\n      MERGE (_person1)-[:HAS_EDUCATION]->(_education1)\\n    \", \"\\n      MATCH (_person1:Person{id:'c1685086177338707569'})\\n      MATCH (_education2:Education{id:'education2'})\\n      MERGE (_person1)-[:HAS_EDUCATION]->(_education2)\\n    \"]\n"
     ]
    }
   ],
   "source": [
    "ent_cyp, rel_cyp = generate_cypher([results])\n",
    "\n",
    "print(ent_cyp, rel_cyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c69170",
   "metadata": {
    "id": "54c69170",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f06013-a653-43cf-be7c-de2888e621f7",
   "metadata": {
    "id": "00f06013-a653-43cf-be7c-de2888e621f7"
   },
   "source": [
    "You will need a Neo4j AuraDS Pro instance.  You can deploy that on Google Cloud Marketplace [here](https://console.cloud.google.com/marketplace/product/endpoints/prod.n4gcp.neo4j.io).\n",
    "\n",
    "With that complete, you'll need to install the Neo4j library and set up your database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a44d36df-21e4-4bad-969e-23ed11762518",
   "metadata": {
    "id": "a44d36df-21e4-4bad-969e-23ed11762518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphdatascience\n",
      "  Downloading graphdatascience-1.6-py3-none-any.whl (918 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.0/919.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multimethod<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from graphdatascience) (1.9.1)\n",
      "Collecting neo4j<6.0,>=4.4.2 (from graphdatascience)\n",
      "  Downloading neo4j-5.8.1.tar.gz (187 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.7/187.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from graphdatascience) (1.5.3)\n",
      "Collecting pyarrow<11.0,>=4.0 (from graphdatascience)\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from graphdatascience) (4.64.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from neo4j<6.0,>=4.4.2->graphdatascience) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0,>=1.0->graphdatascience) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0,>=1.0->graphdatascience) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<2.0,>=1.0->graphdatascience) (1.16.0)\n",
      "Building wheels for collected packages: neo4j\n",
      "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neo4j: filename=neo4j-5.8.1-py3-none-any.whl size=258701 sha256=7a0f2bf53e6440652cb4a1886771cf6c27c68a1e85ea859ba872eb56a2b156e9\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/89/ee/2a/85f7b50c16580f09d88dcdbfd546db95d5b29b9967a3603ca1\n",
      "Successfully built neo4j\n",
      "Installing collected packages: pyarrow, neo4j, graphdatascience\n",
      "\u001b[33m  WARNING: The script plasma_store is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed graphdatascience-1.6 neo4j-5.8.1 pyarrow-10.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user graphdatascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e621c199-533a-4503-baef-200c5adcd8ad",
   "metadata": {
    "id": "e621c199-533a-4503-baef-200c5adcd8ad"
   },
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ecea5ff",
   "metadata": {
    "id": "0ecea5ff"
   },
   "outputs": [],
   "source": [
    "# You will need to change these variables\n",
    "connectionUrl = 'neo4j+s://7c44f42f.databases.neo4j.io'\n",
    "username = 'neo4j'\n",
    "password = 'GRvlpOO4-Ozl8iHaV_20ZQqwOaUljgIpnWyKJRmt2Fc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddbfa6e8",
   "metadata": {
    "id": "ddbfa6e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.6+19'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds = GraphDataScience(connectionUrl, auth=(username, password))\n",
    "gds.version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a3a58",
   "metadata": {
    "id": "228a3a58"
   },
   "source": [
    "Before loading the data, create constraints as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66756bab",
   "metadata": {
    "id": "66756bab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.run_cypher('CREATE CONSTRAINT unique_case_id IF NOT EXISTS FOR (n:Case) REQUIRE n.id IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_person_id IF NOT EXISTS FOR (n:Person) REQUIRE (n.id) IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_symptom_id IF NOT EXISTS FOR (n:Symptom) REQUIRE (n.id) IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_disease_id IF NOT EXISTS FOR (n:Disease) REQUIRE n.id IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_bodysys_id IF NOT EXISTS FOR (n:BodySystem) REQUIRE n.id IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_diag_id IF NOT EXISTS FOR (n:Diagnosis) REQUIRE n.id IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_biological_id IF NOT EXISTS FOR (n:Biological) REQUIRE n.id IS UNIQUE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971bf0b3",
   "metadata": {
    "id": "971bf0b3"
   },
   "source": [
    "Ingest the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7367ece7",
   "metadata": {
    "id": "7367ece7"
   },
   "outputs": [
    {
     "ename": "CypherSyntaxError",
     "evalue": "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '': expected\n  \"ALL\"\n  \"ANY\"\n  \"CASE\"\n  \"COLLECT\"\n  \"COUNT\"\n  \"EXISTS\"\n  \"INF\"\n  \"INFINITY\"\n  \"NAN\"\n  \"NONE\"\n  \"REDUCE\"\n  \"SINGLE\"\n  \"allShortestPaths\"\n  \"false\"\n  \"null\"\n  \"shortestPath\"\n  \"true\"\n  an identifier (line 1, column 62 (offset: 61))\n\"MERGE (_case1:Case{id:'c1685063809776665649'}) ON CREATE SET\"\n                                                              ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/graphdatascience/graph_data_science.py\u001b[0m in \u001b[0;36mrun_cypher\u001b[0;34m(self, query, params, database)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfallback_query_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mqr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdriver_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/graphdatascience/query_runner/neo4j_query_runner.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, query, params, database)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 )\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Though pandas support may be experimental in the `neo4j` package, it should always\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/neo4j/_sync/work/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpersonated_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_access_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mbookmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotifications_min_severity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotifications_disabled_categories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_categories)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_attach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exhausted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNeo4jError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionExpired\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/neo4j/_sync/io/_bolt.py\u001b[0m in \u001b[0;36mfetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydration_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         )\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midle_since\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/neo4j/_sync/io/_bolt5.py\u001b[0m in \u001b[0;36m_process_message\u001b[0;34m(self, tag, fields)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server_state_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_metadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatabaseUnavailable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mon_failure\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_summary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNeo4jError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_ignored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '': expected\n  \"ALL\"\n  \"ANY\"\n  \"CASE\"\n  \"COLLECT\"\n  \"COUNT\"\n  \"EXISTS\"\n  \"INF\"\n  \"INFINITY\"\n  \"NAN\"\n  \"NONE\"\n  \"REDUCE\"\n  \"SINGLE\"\n  \"allShortestPaths\"\n  \"false\"\n  \"null\"\n  \"shortestPath\"\n  \"true\"\n  an identifier (line 1, column 62 (offset: 61))\n\"MERGE (_case1:Case{id:'c1685063809776665649'}) ON CREATE SET\"\n                                                              ^}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for e in ent_cyp:\n",
    "    gds.run_cypher(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f811933",
   "metadata": {
    "id": "0f811933"
   },
   "source": [
    "Ingest relationships now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff4ad1",
   "metadata": {
    "id": "d9ff4ad1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for r in rel_cyp:\n",
    "    gds.run_cypher(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65581a1",
   "metadata": {
    "id": "c65581a1"
   },
   "source": [
    "This is a helper function to ingest all case sheets inside the `data/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707904c",
   "metadata": {
    "id": "b707904c"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "def run_pipeline(count=191):\n",
    "    txt_files = glob.glob(\"data/case_sheets/*.txt\")[0:count]\n",
    "    print(f\"Running pipeline for {len(txt_files)} files\")\n",
    "    failed_files = process_pipeline(txt_files)\n",
    "    print(failed_files)\n",
    "    return failed_files\n",
    "\n",
    "def process_pipeline(files):\n",
    "    failed_files = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            with open(f, 'r') as file:\n",
    "                print(f\"  {f}: Reading File...\")\n",
    "                data = file.read().rstrip()\n",
    "                text = clean_text(data)\n",
    "                print(f\"    {f}: Extracting E & R\")\n",
    "                results = extract_entities_relationships(f, text)\n",
    "                print(f\"    {f}: Generating Cypher\")\n",
    "                ent_cyp, rel_cyp = generate_cypher(results)\n",
    "                print(f\"    {f}: Ingesting Entities\")\n",
    "                for e in ent_cyp:\n",
    "                    gds.run_cypher(e)\n",
    "                print(f\"    {f}: Ingesting Relationships\")\n",
    "                for r in rel_cyp:\n",
    "                    gds.run_cypher(r)\n",
    "                print(f\"    {f}: Processing DONE\")\n",
    "        except Exception as e:\n",
    "            print(f\"    {f}: Processing Failed with exception {e}\")\n",
    "            failed_files.append(f)\n",
    "    return failed_files\n",
    "            \n",
    "def extract_entities_relationships(f, text):\n",
    "    start = timer()\n",
    "    system = \"You are a helpful Medical Case Sheet expert who extracts relevant information and store them on a Neo4j Knowledge Graph\"\n",
    "    prompts = [prompt1]\n",
    "    all_cypher = \"\"\n",
    "    results = []\n",
    "    for p in prompts:\n",
    "      p = Template(p).substitute(ctext=text)\n",
    "      res = process_gpt(system, p)\n",
    "      results.append(json.loads(res))\n",
    "    end = timer()\n",
    "    elapsed = (end-start)\n",
    "    print(f\"    {f}: E & R took {elapsed}secs\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b86a7",
   "metadata": {
    "id": "bb4b86a7"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "failed_files = run_pipeline(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e9c48",
   "metadata": {
    "id": "653e9c48"
   },
   "source": [
    "If processing failed for some files due to API Rate limit or some other error, you can retry as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26a851",
   "metadata": {
    "id": "4e26a851"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "failed_files = process_pipeline(failed_files)\n",
    "failed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77de32",
   "metadata": {
    "id": "4d77de32"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UrvbzyY_X8uP",
   "metadata": {
    "id": "UrvbzyY_X8uP"
   },
   "source": [
    "## Cypher Generation for Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c06e57d-72a9-4b86-8b8d-119690895c02",
   "metadata": {},
   "source": [
    "### Tune the model to generate Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316e464-5dbf-475d-8507-de07ba0bc0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = 'gs://' + bucket_name + '/' + filename\n",
    "train_steps = 10\n",
    "\n",
    "vertexai.init(project=project_id, location=location)\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "model.tune_model(\n",
    "  training_data=training_data,\n",
    "  train_steps=train_steps,\n",
    "  tuning_job_location=\"europe-west4\",\n",
    "  tuned_model_location=\"us-central1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113928b-b83d-4f41-833b-a92e851cca3a",
   "metadata": {},
   "source": [
    "### Generate Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e9f2895-c3c4-401c-a4d6-cf1b80a2050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_to_cypher(prompt, tuned_model_name=''):\n",
    "    try:\n",
    "        res = run_text_model(project_id, \"text-bison@001\", 0, 1024, 0.8, 40, prompt, location, tuned_model_name)\n",
    "        # res = json.loads(res.replace(\"\\'\", \"'\"))\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "EMZysiC9YsqC",
   "metadata": {
    "id": "EMZysiC9YsqC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MATCH (p:Person)-[:HAS_EDUCATION]->(e:Education) RETURN e.university ORDER BY COUNT(e) DESC LIMIT 10'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Context:\n",
    "You are an expert Neo4j Cypher translator who understands the question in english and convert to Cypher strictly based on the Neo4j Schema provided and the instructions below:\n",
    "1. Use the Neo4j schema to generate cypher compatible ONLY for Neo4j Version 5\n",
    "2. Do not use EXISTS, SIZE keywords in the cypher.\n",
    "3. Use only Nodes and relationships mentioned in the schema while generating the response\n",
    "4. Reply ONLY in Cypher\n",
    "5. Always do a case-insensitive and fuzzy search for any properties related search. Eg: to search for a Company name use `toLower(c.name) contains 'neo4j'`\n",
    "6. Candidate node is synonymous to Person.\n",
    "Now, use this Neo4j schema and Reply ONLY in Cypher when it makes sense.\n",
    "Schema:\n",
    "Nodes:\n",
    "    label:'Person',id:string,role:string,description:string //Person Node\n",
    "    label:'Position',id:string,title:string,location:string,startDate:string,endDate:string,url:string //Position Node\n",
    "    label:'Company',id:string,name:string //Company Node\n",
    "    label:'Skill',id:string,name:string,level:string //Skill Node\n",
    "    label:'Education',id:string,degree:string,university:string,graduation_date:string,score:string,url:string,courses:string //Education Node\n",
    "Relationships:\n",
    "    (:Person)-[:HAS_POSITION]->(:Position)\n",
    "    (:Position)-[:AT_COMPANY]->(:Company)\n",
    "    (:Person)-[:HAS_SKILL]->(:Skill)\n",
    "    (:Person)-[:HAS_EDUCATION]->(:Education)\n",
    "\n",
    "So, for this question: 'How many experts do I have on Java', you will answer : MATCH (p:Person)-[:HAS_SKILL]->(s:Skill) WHERE toLower(p.name) CONTAINS 'java' AND toLower(p.level) CONTAINS 'expert' RETURN COUNT(p) \n",
    "Because:\n",
    "1. As per schema definition of nodes & relationships above, Person node is related to Skill node via HAS_SKILL relationship.\n",
    "2. From the schema, Skill has name and levels as properties. Expertise can be checked using `level`\n",
    "3. Finally, we return the number of persons who match the input criteria using COUNT function\n",
    "\n",
    "\n",
    "Ouput Format (Strict): //Only code as output. No other text\n",
    "MATCH (p:Person)-[:HAS_SKILL]->(s:Skill) WHERE toLower(p.name) CONTAINS 'java' AND toLower(p.level) CONTAINS 'expert' RETURN COUNT(p) \n",
    "\n",
    "Question:\n",
    "$ctext\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "que = 'Which universities do most of my candidates come from?'\n",
    "_prompt = Template(prompt).substitute(ctext=clean_text(que))\n",
    "\n",
    "cypher = english_to_cypher(_prompt, '')\n",
    "if 'Answer:\\n ' in response:\n",
    "    cypher = cypher.split('Answer:\\n ')[1]\n",
    "cypher\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad060d0-e38a-4b0e-996a-c7307d225d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
