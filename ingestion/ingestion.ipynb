{"cells":[{"attachments":{},"cell_type":"markdown","id":"3d3d39ab","metadata":{"id":"3d3d39ab"},"source":["# LLM Powered Medical Case Sheet Ingestion\n","## Outline\n","1. Data Cleansing\n","2. Prompt Definition\n","3. Entity & Relationship Extraction\n","4. Neo4j Cypher Generation\n","5. Data Ingestion"]},{"cell_type":"code","execution_count":1,"id":"MIA5EowyHP1P","metadata":{"executionInfo":{"elapsed":11740,"status":"ok","timestamp":1684243975144,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"MIA5EowyHP1P"},"outputs":[],"source":["from google.colab import auth as google_auth\n","google_auth.authenticate_user()"]},{"cell_type":"code","execution_count":2,"id":"f7a24c30","metadata":{"executionInfo":{"elapsed":52671,"status":"ok","timestamp":1684244027811,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"f7a24c30"},"outputs":[],"source":["%%capture\n","%pip install graphdatascience\n","%pip install python-dotenv\n","%pip install retry\n","!gsutil cp gs://vertex_sdk_llm_private_releases/SDK/google_cloud_aiplatform-1.25.dev20230413+language.models-py2.py3-none-any.whl .\n","%pip install ./google_cloud_aiplatform-1.25.dev20230413+language.models-py2.py3-none-any.whl \"shapely<2.0.0\" --force-reinstall"]},{"cell_type":"code","execution_count":3,"id":"b2932853","metadata":{"executionInfo":{"elapsed":3538,"status":"ok","timestamp":1684244038879,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"b2932853"},"outputs":[],"source":["import os\n","from retry import retry\n","import re\n","from string import Template\n","import json \n","import ast\n","import time\n","import pandas as pd\n","from graphdatascience import GraphDataScience\n","import glob\n","from timeit import default_timer as timer\n","from dotenv import load_dotenv\n","\n","from google.cloud import aiplatform\n","from google.cloud.aiplatform.private_preview.language_models import ChatModel, InputOutputTextPair"]},{"attachments":{},"cell_type":"markdown","id":"707d388e","metadata":{},"source":["The training below shows how to instruction-tune a text-bison model. chat-bison model which we are going to use in the ingestion process is currently tunable. The below code is meant to show an example of fine-tuning"]},{"cell_type":"code","execution_count":4,"id":"xUJ785QJbNZ-","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1684244038879,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"xUJ785QJbNZ-"},"outputs":[],"source":["from typing import Union\n","\n","import pandas as pd\n","\n","from google.cloud.aiplatform.private_preview.language_models import TextGenerationModel\n","from google.cloud import aiplatform\n","\n","\n","def tune_model(\n","    project_id: str,\n","    location: str,\n","    training_data: Union[pd.DataFrame, str],\n","    train_steps: int = 10,\n","):\n","  \"\"\"Tune a new model, based on a prompt-response data.\n","\n","  \"training_data\" can be either the GCS URI of a file formatted in JSONL format\n","  (for example: training_data=f'gs://{bucket}/{filename}.jsonl'), or a pandas\n","  DataFrame. Each training example should be JSONL record with two keys, for\n","  example:\n","    {\n","      \"input_text\": <input prompt>,\n","      \"output_text\": <associated output>\n","    },\n","  or the pandas DataFame should contain two columns:\n","    ['input_text', 'output_text']\n","  with rows for each training example.\n","\n","  Args:\n","    project_id: GCP Project ID, used to initialize aiplatform\n","    location: GCP Region, used to initialize aiplatform\n","    training_data: GCS URI of training file or pandas dataframe of training data\n","    train_steps: Number of training steps to use when tuning the model.\n","  \"\"\"\n","  aiplatform.init(project=project_id, location=location)\n","  model = TextGenerationModel.from_pretrained(\"text-bison-001\")\n","\n","  model.tune_model(\n","      training_data=training_data,\n","      train_steps=train_steps,\n","      tuning_job_location=\"europe-west4\",\n","      tuned_model_location=\"us-central1\",\n","  )\n","\n","  # Test the tuned model:\n","  print(\n","      model.predict(\"Tell me some ideas combining VR and fitness:\")\n","  )"]},{"cell_type":"code","execution_count":null,"id":"7u2RiDh9bdle","metadata":{"id":"7u2RiDh9bdle"},"outputs":[],"source":["tune_model('neo4jbusinessdev', 'us-central1',\n","    'gs://gs_vertex_ai/eng2cypher/eng2cypher.jsonl',10\n","           )"]},{"cell_type":"code","execution_count":12,"id":"LXK2Bxm_yLmc","metadata":{"executionInfo":{"elapsed":340,"status":"ok","timestamp":1684244323454,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"LXK2Bxm_yLmc"},"outputs":[],"source":["from google.cloud.aiplatform.private_preview.language_models import TextGenerationModel\n","from google.cloud import aiplatform\n","\n","\n","def list_tuned_models(project_id, location):\n","  \"\"\"List tuned models.\"\"\"\n","  aiplatform.init(project=project_id, location=location)\n","  model = TextGenerationModel.from_pretrained(\"text-bison-001\")\n","  tuned_model_names = model.list_tuned_model_names()\n","  print(tuned_model_names)"]},{"attachments":{},"cell_type":"markdown","id":"48db2e49","metadata":{"id":"48db2e49"},"source":["## Data Cleansing"]},{"attachments":{},"cell_type":"markdown","id":"10113a08","metadata":{"id":"10113a08"},"source":["First, let's define a function that can help clean the input data. For the sake of simplicity, lets keep it simple. In the corpus, the data refers to some Figures like scan images. We dont have them and so will remove any such references."]},{"cell_type":"code","execution_count":5,"id":"e430a536","metadata":{"executionInfo":{"elapsed":534,"status":"ok","timestamp":1684244050391,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"e430a536"},"outputs":[],"source":["def clean_text(text):\n","  clean = \"\\n\".join([row for row in text.split(\"\\n\")])\n","  clean = re.sub(r'\\(fig[^)]*\\)', '', clean, flags=re.IGNORECASE)\n","  return clean"]},{"attachments":{},"cell_type":"markdown","id":"72960046","metadata":{"id":"72960046"},"source":["Let's take this case sheet and extract entities and relations using LLM"]},{"cell_type":"code","execution_count":6,"id":"e9cc20d7","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684244050904,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"e9cc20d7"},"outputs":[],"source":["sample_que = \"\"\"The patient was a 34-yr-old man who presented with complaints of fever and a chronic cough.\n","He was a smoker and had a history of pulmonary tuberculosis that had been treated and cured.\n","A computed tomographic (CT) scan revealed multiple tiny nodules in both lungs.\n","A thoracoscopic lung biopsy was taken from the right upper lobe.\n","The microscopic examination revealed a typical LCH.\n","The tumor cells had vesicular and grooved nuclei, and they formed small aggregations around the bronchioles (Fig.1).\n","The tumor cells were strongly positive for S-100 protein, vimentin, CD68 and CD1a.\n","There were infiltrations of lymphocytes and eosinophils around the tumor cells.\n","With performing additional radiologic examinations, no other organs were thought to be involved.\n","He quit smoking, but he received no other specific treatment.\n","He was well for the following one year.\n","After this, a follow-up CT scan was performed and it showed a 4 cm-sized mass in the left lower lobe, in addition to the multiple tiny nodules in both lungs (Fig.2).\n","A needle biopsy specimen revealed the possibility of a sarcoma; therefore, a lobectomy was performed.\n","Grossly, a 4 cm-sized poorly-circumscribed lobulated gray-white mass was found (Fig.3), and there were a few small satellite nodules around the main mass.\n","Microscopically, the tumor cells were aggregated in large sheets and they showed an infiltrative growth.\n","The cytologic features of some of the tumor cells were similar to those seen in a typical LCH.\n","However, many tumor cells showed overtly malignant cytologic features such as pleomorphic/hyperchromatic nuclei and prominent nucleoli (Fig.4), and multinucleated tumor giant cells were also found.\n","There were numerous mitotic figures ranging from 30 to 60 per 10 high power fields, and some of them were abnormal.\n","A few foci of typical LCH remained around the main tumor mass.\n","Immunohistochemically, the tumor cells were strongly positive for S-100 protein (Fig.5) and vimentin; they were also positive for CD68 (Dako N1577, Clone KPI), and focally positive for CD1a (Fig.6), and they were negative for cytokeratin, epithelial membrane antigen, CD3, CD20 and HMB45.\n","The ultrastructural analysis failed to demonstrate any Birbeck granules in the cytoplasm of the tumor cells.\n","Now, at five months after lobectomy, the patient is doing well with no significant change in the radiologic findings.\n","\"\"\"\n","\n","sample_ans = \"\"\"\n","{'entities': [{'label': 'Case',\n","    'id': 'case1',\n","    'summary': '34-yr-old man with fever, chronic cough, history of pulmonary tuberculosis, LCH diagnosis, and sarcoma. Underwent lobectomy and is doing well.'},\n","   {'label': 'Person',\n","    'id': 'person1',\n","    'age': '34',\n","    'location': '',\n","    'gender': 'male'},\n","   {'label': 'Symptom', 'id': 'fever', 'description': 'Fever'},\n","   {'label': 'Symptom', 'id': 'chronicCough', 'description': 'Chronic cough'},\n","   {'label': 'Disease',\n","    'id': 'pulmonaryTuberculosis',\n","    'name': 'Pulmonary Tuberculosis'},\n","   {'label': 'Disease',\n","    'id': 'langerhansCellHistiocytosis',\n","    'name': 'Langerhans Cell Histiocytosis'},\n","   {'label': 'Disease', 'id': 'sarcoma', 'name': 'Sarcoma'},\n","   {'label': 'BodySystem', 'id': 'lungs', 'name': 'Lungs'},\n","   {'label': 'BodySystem', 'id': 'heart', 'name': 'Heart'},\n","   {'label': 'Diagnosis',\n","    'id': 'ctScan',\n","    'name': 'CT Scan',\n","    'description': 'Computed Tomographic (CT) scan',\n","    'when': 'initial'},\n","   {'label': 'Diagnosis',\n","    'id': 'thoracoscopicLungBiopsy',\n","    'name': 'Thoracoscopic Lung Biopsy',\n","    'description': 'Thoracoscopic lung biopsy from the right upper lobe',\n","    'when': 'initial'},\n","   {'label': 'Diagnosis',\n","    'id': 'followUpCtScan',\n","    'name': 'Follow-up CT Scan',\n","    'description': 'Follow-up CT scan showing a 4 cm-sized mass in the left lower lobe',\n","    'when': 'one year later'},\n","   {'label': 'Diagnosis',\n","    'id': 'needleBiopsy',\n","    'name': 'Needle Biopsy',\n","    'description': 'Needle biopsy specimen revealing the possibility of a sarcoma',\n","    'when': 'one year later'},\n","   {'label': 'Diagnosis',\n","    'id': 'lobectomy',\n","    'name': 'Lobectomy',\n","    'description': 'Lobectomy performed to remove the mass',\n","    'when': 'one year later'},\n","   {'label': 'Biological',\n","    'id': 'multipleTinyNodules',\n","    'name': 'Multiple Tiny Nodules',\n","    'description': 'Multiple tiny nodules in both lungs'},\n","   {'label': 'Biological',\n","    'id': 'lchCells',\n","    'name': 'LCH Cells',\n","    'description': 'Typical LCH cells with vesicular and grooved nuclei'},\n","   {'label': 'Biological',\n","    'id': 'tumorCells',\n","    'name': 'Tumor Cells',\n","    'description': 'Tumor cells with malignant cytologic features'}],\n","  'relationships': ['case1|FOR|person1',\n","   \"person1|HAS_SYMPTOM{when:'initial',frequency:'',span:''}|fever\",\n","   \"person1|HAS_SYMPTOM{when:'initial',frequency:'',span:''}|chronicCough\",\n","   \"person1|HAS_DISEASE{when:'past'}|pulmonaryTuberculosis\",\n","   \"person1|HAS_DISEASE{when:'initial'}|langerhansCellHistiocytosis\",\n","   \"person1|HAS_DISEASE{when:'one year later'}|sarcoma\",\n","   'chronicCough|SEEN_ON|lungs',\n","   'langerhansCellHistiocytosis|AFFECTS|lungs',\n","   'sarcoma|AFFECTS|lungs',\n","   'person1|HAS_DIAGNOSIS|ctScan',\n","   'person1|HAS_DIAGNOSIS|thoracoscopicLungBiopsy',\n","   'person1|HAS_DIAGNOSIS|followUpCtScan',\n","   'person1|HAS_DIAGNOSIS|needleBiopsy',\n","   'person1|HAS_DIAGNOSIS|lobectomy',\n","   'ctScan|SHOWED|multipleTinyNodules',\n","   'thoracoscopicLungBiopsy|SHOWED|lchCells',\n","   'lobectomy|SHOWED|tumorCells']}\n","\"\"\"\n","\n","que = \"\"\"A 28-year-old previously healthy man presented with a 6-week history of palpitations.\n","The symptoms occurred during rest, 2–3 times per week, lasted up to 30 minutes at a time and were associated with dyspnea.\n","Except for a grade 2/6 holosystolic tricuspid regurgitation murmur (best heard at the left sternal border with inspiratory accentuation), physical examination yielded unremarkable findings.\n","An electrocardiogram (ECG) revealed normal sinus rhythm and a Wolff– Parkinson– White pre-excitation pattern (Fig.1: Top), produced by a right-sided accessory pathway.\n","Transthoracic echocardiography demonstrated the presence of Ebstein's anomaly of the tricuspid valve, with apical displacement of the valve and formation of an “atrialized” right ventricle (a functional unit between the right atrium and the inlet [inflow] portion of the right ventricle) (Fig.2).\n","The anterior tricuspid valve leaflet was elongated (Fig.2C, arrow), whereas the septal leaflet was rudimentary (Fig.2C, arrowhead).\n","Contrast echocardiography using saline revealed a patent foramen ovale with right-to-left shunting and bubbles in the left atrium (Fig.2D).\n","The patient underwent an electrophysiologic study with mapping of the accessory pathway, followed by radiofrequency ablation (interruption of the pathway using the heat generated by electromagnetic waves at the tip of an ablation catheter).\n","His post-ablation ECG showed a prolonged PR interval and an odd “second” QRS complex in leads III, aVF and V2–V4 (Fig.1Bottom), a consequence of abnormal impulse conduction in the “atrialized” right ventricle.\n","The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.\n","\n","\"\"\""]},{"attachments":{},"cell_type":"markdown","id":"4e43bb3c","metadata":{"id":"4e43bb3c"},"source":["## Prompt Definition"]},{"attachments":{},"cell_type":"markdown","id":"3938880e","metadata":{"id":"3938880e"},"source":["**⚠️** You need to duplicate `config.env.example` file in the left and rename as `config.env`. Edit the values in this file and provide the values for API keys and Neo4j credentials"]},{"cell_type":"code","execution_count":7,"id":"WypXZ0cG54ub","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22132,"status":"ok","timestamp":1684244075910,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"WypXZ0cG54ub","outputId":"e7b28af2-b5fb-44c4-9b11-8e0afb62ce95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":8,"id":"8cd7d619","metadata":{"executionInfo":{"elapsed":1998,"status":"ok","timestamp":1684244153255,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"8cd7d619"},"outputs":[],"source":["load_dotenv('/content/drive/MyDrive/Colab Notebooks/GenAI-Playground/config-gcp.env', override=True)\n","\n","shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n","PROJECT_ID = os.getenv('PROJECT_ID')\n","os.environ[\"GCLOUD_PROJECT\"] = PROJECT_ID\n","os.environ['GCLOUD_REGION'] = 'us-central1'"]},{"cell_type":"code","execution_count":null,"id":"043a2599","metadata":{},"outputs":[],"source":["list_tuned_models(PROJECT_ID, 'europe-west4')"]},{"attachments":{},"cell_type":"markdown","id":"605ad98c","metadata":{"id":"605ad98c"},"source":["This is a helper function to talk to the LLM with our prompt and text input"]},{"cell_type":"code","execution_count":9,"id":"1148d87e","metadata":{"executionInfo":{"elapsed":331,"status":"ok","timestamp":1684244155169,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"1148d87e"},"outputs":[],"source":["# Bison Prompt to complete\n","@retry(tries=2, delay=5)\n","def process_gpt(\n","    project_id: str,\n","    model_name: str,\n","    temperature: float,\n","    max_output_tokens: int,\n","    top_p: float,\n","    top_k: int,\n","    prompt: str,\n","    que: str,\n","    location: str = \"us-central1\",\n","    ) :\n","    \"\"\"Predict using a Large Language Model.\"\"\"\n","    aiplatform.init(project=project_id, location=location)\n","\n","    chat_model = ChatModel.from_pretrained(model_name)\n","    parameters = {\n","      \"temperature\": temperature,\n","      \"max_output_tokens\": max_output_tokens,\n","      \"top_p\": top_p,\n","      \"top_k\": top_k,\n","    }\n","\n","    chat = chat_model.start_chat(\n","      context='''You are a helpful Medical Case Sheet expert who extracts relevant information which will be eventually used to store them on a Neo4j Knowledge Graph after processing''',\n","      examples=[\n","        InputOutputTextPair(\n","          input_text=prompt+sample_que,\n","          output_text=sample_ans\n","        )\n","      ]\n","    )\n","    return chat.send_message(prompt+que,**parameters)\n"]},{"attachments":{},"cell_type":"markdown","id":"7781a12b","metadata":{"id":"7781a12b"},"source":["This is a simple prompt to start with. If the processing is very complex, you can also chain the prompts as and when required. I am going to use a single prompt here that helps me to extract the text strictly as per the Entities and Relationships defined. This is a simplification. In the real scenario, especially with medical records, you have to leverage on Domain experts to define the Ontology systematically and capture the important information. You might also be fine-tuning the model as and when required.\n","\n","Also, instead of one single large model, you can also consider chaining a number of smaller ones as per your needs.\n","\n","We are going with this Graph Schema for our Case Sheet:\n","![schema.png](schema.png)"]},{"cell_type":"code","execution_count":10,"id":"7921fa85","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684244159006,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"7921fa85"},"outputs":[],"source":["prompt=\"\"\"From the Case sheet for a patient below, extract the following Entities & relationships described in the mentioned format \n","0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n","1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n","   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. Document must be summarized and stored inside Case entity under `summary` property. You will have to generate as many entities as needed as per the types below:\n","    Entity Types:\n","    label:'Case',id:string,summary:string //Case\n","    label:'Person',id:string,age:string,location:string,gender:string //Patient mentioned in the case\n","    label:'Symptom',id:string,description:string //Symptom Entity; `id` property is the name of the symptom, in lowercase & camel-case & should always start with an alphabet\n","    label:'Disease',id:string,name:string //Disease diagnosed now or previously as per the Case sheet; `id` property is the name of the disease, in lowercase & camel-case & should always start with an alphabet\n","    label:'BodySystem',id:string,name:string //Body Part affected. Eg: Chest, Lungs; id property is the name of the part, in lowercase & camel-case & should always start with an alphabet\n","    label:'Diagnosis',id:string,name:string,description:string,when:string //Diagnostic procedure conducted; `id` property is the summary of the Diagnosis, in lowercase & camel-case & should always start with an alphabet\n","    label:'Biological',id:string,name:string,description:string //Results identified from Diagnosis; `id` property is the summary of the Biological, in lowercase & camel-case & should always start with an alphabet\n","    \n","3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n","    Relationship types:\n","    case|FOR|person\n","    person|HAS_SYMPTOM{when:string,frequency:string,span:string}|symptom //the properties inside HAS_SYMPTOM gets populated from the Case sheet\n","    person|HAS_DISEASE{when:string}|disease //the properties inside HAS_DISEASE gets populated from the Case sheet\n","    symptom|SEEN_ON|chest\n","    disease|AFFECTS|heart\n","    person|HAS_DIAGNOSIS|diagnosis\n","    diagnosis|SHOWED|biological\n","4. Do not send any response other than code block in the response\n","\n","The output should look like :\n","{\n","    \"entities\": [{\"label\":\"Case\",\"id\":string,\"summary\":string}],\n","    \"relationships\": [\"disease|AFFECTS|heart\"]\n","}\n","\n","Case Sheet:\n","$ctext\n","\"\"\""]},{"attachments":{},"cell_type":"markdown","id":"d2b4f9a9","metadata":{"id":"d2b4f9a9"},"source":["Let's run our completion task with our LLM"]},{"cell_type":"code","execution_count":19,"id":"dcbfd725","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5270,"status":"ok","timestamp":1684244486812,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"dcbfd725","outputId":"98daeb6b-5491-4a7b-8e6e-4815a88feed6"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:retry.api:Unknown model name 'projects/803648085855/locations/us-central1/models/7947351409425383424'. Available model names are: ['text-bison-001', 'text-bison-alpha', 'embedding-gecko-001', 'chat-bison-001'], retrying in 5 seconds...\n"]},{"name":"stdout","output_type":"stream","text":["Unknown model name 'projects/803648085855/locations/us-central1/models/7947351409425383424'. Available model names are: ['text-bison-001', 'text-bison-alpha', 'embedding-gecko-001', 'chat-bison-001']\n","CPU times: user 33.2 ms, sys: 974 µs, total: 34.2 ms\n","Wall time: 5.01 s\n"]}],"source":["%%time\n","def run_completion(prompt, results, ctext):\n","    try:\n","      pr = Template(prompt).substitute(ctext=ctext)\n","      res = process_gpt(PROJECT_ID,\n","                        'chat-bison-001'\n","                        , 0, 1024, 0.8, 40, prompt, que, location=\"us-central1\")\n","      results.append(res)\n","      return results\n","    except Exception as e:\n","        print(e)\n","\n","prompts = [prompt]\n","results = []\n","for p in prompts:\n","  results = run_completion(p, results, clean_text(sample_que))\n","    "]},{"cell_type":"code","execution_count":13,"id":"N_4Ub0umK6xI","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1684139871699,"user":{"displayName":"Ezhil Vendhan","userId":"03023723423453260577"},"user_tz":-480},"id":"N_4Ub0umK6xI","outputId":"fde8a657-ae51-4730-e5ae-4b5fb24d4fa8"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Sure, here are the entities and relationships extracted from the case sheet:\\n\\nEntities:\\n\\n* Case:\\n    * label: 'Case'\\n    * id: 'case1'\\n    * summary: '28-year-old man with palpitations, Ebstein's anomaly, and Wolff– Parkinson– White pre-excitation pattern. Underwent radiofrequency ablation and is doing well.'\\n* Person:\\n    * label: 'Person'\\n    * id: 'person1'\\n    * age: '28'\\n    * location: ''\\n    * gender: 'male'\\n* Symptom:\\n    * label: 'Palpitations'\\n    * id: 'palpitations'\\n    * description: 'Palpitations occurred during rest, 2–3 times per week, lasted up to 30 minutes at a time and were associated with dyspnea.'\\n* Disease:\\n    * label: 'Ebstein's anomaly'\\n    * id: 'ebsteinsAnomaly'\\n    * name: 'Ebstein's anomaly'\\n* BodySystem:\\n    * label: 'Heart'\\n    * id: 'heart'\\n    * name: 'Heart'\\n* Diagnosis:\\n    * label: 'Electrophysiologic study'\\n    * id: 'electrophysiologicStudy'\\n    * name: 'Electrophysiologic study'\\n    * description: 'Mapping of the accessory pathway, followed by radiofrequency ablation (interruption of the pathway using the heat generated by electromagnetic waves at the tip of an ablation catheter).'\\n* Biological:\\n    * label: 'Abnormal impulse conduction'\\n    * id: 'abnormalImpulseConduction'\\n    * name: 'Abnormal impulse conduction'\\n    * description: 'A consequence of abnormal impulse conduction in the “atrialized” right ventricle.'\\n\\nRelationships:\\n\\n* case|FOR|person\\n* person|HAS_SYMPTOM{when:'',frequency:'',span:''}|symptom\\n* person|HAS_DISEASE{when:''}|disease\\n* symptom|SEEN_ON|bodySystem\\n* disease|AFFECTS|bodySystem\\n* person|HAS_DIAGNOSIS|diagnosis\\n* diagnosis|SHOWED|biological\""]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["results[0].text"]},{"attachments":{},"cell_type":"markdown","id":"8feb2a60","metadata":{"id":"8feb2a60"},"source":["## Neo4j Cypher Generation"]},{"attachments":{},"cell_type":"markdown","id":"0b96efc5","metadata":{"id":"0b96efc5"},"source":["The entities & relationships we got from the LLM have to be transformed to Cypher so we can ingest into Neo4j"]},{"cell_type":"code","execution_count":null,"id":"084047d0","metadata":{"id":"084047d0"},"outputs":[],"source":["#pre-processing results for uploading into Neo4j - helper function:\n","def get_prop_str(prop_dict, _id):\n","    s = []\n","    for key, val in prop_dict.items():\n","      if key != 'label' and key != 'id':\n","         s.append(_id+\".\"+key+' = \"'+str(val).replace('\\\"', '\"').replace('\"', '\\\"')+'\"') \n","    return ' ON CREATE SET ' + ','.join(s)\n","\n","def get_cypher_compliant_var(_id):\n","    return \"_\"+ re.sub(r'[\\W_]', '', _id)\n","\n","def generate_cypher(in_json):\n","    e_map = {}\n","    e_stmt = []\n","    r_stmt = []\n","    e_stmt_tpl = Template(\"($id:$label{id:'$key'})\")\n","    r_stmt_tpl = Template(\"\"\"\n","      MATCH $src\n","      MATCH $tgt\n","      MERGE ($src_id)-[:$rel]->($tgt_id)\n","    \"\"\")\n","    for obj in in_json:\n","      for j in obj['entities']:\n","          props = ''\n","          label = j['label']\n","          id = j['id']\n","          if label == 'Case':\n","                id = 'c'+str(time.time_ns())\n","          elif label == 'Person':\n","                id = 'p'+str(time.time_ns())\n","          varname = get_cypher_compliant_var(j['id'])\n","          stmt = e_stmt_tpl.substitute(id=varname, label=label, key=id)\n","          e_map[varname] = stmt\n","          e_stmt.append('MERGE '+ stmt + get_prop_str(j, varname))\n","\n","      for st in obj['relationships']:\n","          rels = st.split(\"|\")\n","          src_id = get_cypher_compliant_var(rels[0].strip())\n","          rel = rels[1].strip()\n","          tgt_id = get_cypher_compliant_var(rels[2].strip())\n","          stmt = r_stmt_tpl.substitute(\n","              src_id=src_id, tgt_id=tgt_id, src=e_map[src_id], tgt=e_map[tgt_id], rel=rel)\n","          \n","          r_stmt.append(stmt)\n","\n","    return e_stmt, r_stmt"]},{"cell_type":"code","execution_count":null,"id":"ec143b14","metadata":{"id":"ec143b14"},"outputs":[],"source":["ent_cyp, rel_cyp = generate_cypher(results)"]},{"attachments":{},"cell_type":"markdown","id":"54c69170","metadata":{"id":"54c69170"},"source":["## Data Ingestion"]},{"cell_type":"code","execution_count":null,"id":"0ecea5ff","metadata":{"id":"0ecea5ff"},"outputs":[],"source":["connectionUrl = os.getenv('NEO4J_CONN_URL')\n","username = os.getenv('NEO4J_USER')\n","password = os.getenv('NEO4J_PASSWORD')"]},{"cell_type":"code","execution_count":null,"id":"ddbfa6e8","metadata":{"id":"ddbfa6e8","outputId":"0e421a11-6609-4bef-c426-404459f6cb9d"},"outputs":[{"data":{"text/plain":["'2.3.4+17'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["gds = GraphDataScience(connectionUrl, auth=(username, password))\n","gds.version()"]},{"attachments":{},"cell_type":"markdown","id":"228a3a58","metadata":{"id":"228a3a58"},"source":["Before loading the data, create constraints as below"]},{"cell_type":"code","execution_count":null,"id":"66756bab","metadata":{"id":"66756bab","outputId":"67c5f624-1389-48be-c089-11b712183e0f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["gds.run_cypher('CREATE CONSTRAINT unique_case_id IF NOT EXISTS FOR (n:Case) REQUIRE n.id IS UNIQUE')\n","gds.run_cypher('CREATE CONSTRAINT unique_person_id IF NOT EXISTS FOR (n:Person) REQUIRE (n.id) IS UNIQUE')\n","gds.run_cypher('CREATE CONSTRAINT unique_symptom_id IF NOT EXISTS FOR (n:Symptom) REQUIRE (n.id) IS UNIQUE')\n","gds.run_cypher('CREATE CONSTRAINT unique_disease_id IF NOT EXISTS FOR (n:Disease) REQUIRE n.id IS UNIQUE')\n","gds.run_cypher('CREATE CONSTRAINT unique_bodysys_id IF NOT EXISTS FOR (n:BodySystem) REQUIRE n.id IS UNIQUE')\n","gds.run_cypher('CREATE CONSTRAINT unique_diag_id IF NOT EXISTS FOR (n:Diagnosis) REQUIRE n.id IS UNIQUE')\n","gds.run_cypher('CREATE CONSTRAINT unique_biological_id IF NOT EXISTS FOR (n:Biological) REQUIRE n.id IS UNIQUE')"]},{"attachments":{},"cell_type":"markdown","id":"971bf0b3","metadata":{"id":"971bf0b3"},"source":["Ingest the entities"]},{"cell_type":"code","execution_count":null,"id":"7367ece7","metadata":{"id":"7367ece7","outputId":"cca33a34-048b-4922-f54b-edda8a8da773"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 35.4 ms, sys: 0 ns, total: 35.4 ms\n","Wall time: 1.49 s\n"]}],"source":["%%time\n","for e in ent_cyp:\n","    gds.run_cypher(e)\n"]},{"attachments":{},"cell_type":"markdown","id":"0f811933","metadata":{"id":"0f811933"},"source":["Ingest relationships now"]},{"cell_type":"code","execution_count":null,"id":"d9ff4ad1","metadata":{"id":"d9ff4ad1","outputId":"302304cf-e504-4ed2-b305-7822ef14162f"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 51.5 ms, sys: 0 ns, total: 51.5 ms\n","Wall time: 2.72 s\n"]}],"source":["%%time\n","for r in rel_cyp:\n","    gds.run_cypher(r)"]},{"attachments":{},"cell_type":"markdown","id":"c65581a1","metadata":{"id":"c65581a1"},"source":["This is a helper function to ingest all case sheets inside the `data/` directory"]},{"cell_type":"code","execution_count":null,"id":"b707904c","metadata":{"id":"b707904c"},"outputs":[],"source":["def run_pipeline(count=191):\n","    txt_files = glob.glob(\"data/case_sheets/*.txt\")[0:count]\n","    print(f\"Running pipeline for {len(txt_files)} files\")\n","    failed_files = process_pipeline(txt_files)\n","    print(failed_files)\n","    return failed_files\n","\n","def process_pipeline(files):\n","    failed_files = []\n","    for f in files:\n","        try:\n","            with open(f, 'r') as file:\n","                print(f\"  {f}: Reading File...\")\n","                data = file.read().rstrip()\n","                text = clean_text(data)\n","                print(f\"    {f}: Extracting E & R\")\n","                results = extract_entities_relationships(f, text)\n","                print(f\"    {f}: Generating Cypher\")\n","                ent_cyp, rel_cyp = generate_cypher(results)\n","                print(f\"    {f}: Ingesting Entities\")\n","                for e in ent_cyp:\n","                    gds.run_cypher(e)\n","                print(f\"    {f}: Ingesting Relationships\")\n","                for r in rel_cyp:\n","                    gds.run_cypher(r)\n","                print(f\"    {f}: Processing DONE\")\n","        except Exception as e:\n","            print(f\"    {f}: Processing Failed with exception {e}\")\n","            failed_files.append(f)\n","    return failed_files\n","            \n","def extract_entities_relationships(f, text):\n","    start = timer()\n","    system = \"You are a helpful Medical Case Sheet expert who extracts relevant information and store them on a Neo4j Knowledge Graph\"\n","    prompts = [prompt1]\n","    all_cypher = \"\"\n","    results = []\n","    for p in prompts:\n","      p = Template(p).substitute(ctext=text)\n","      res = process_gpt(system, p)\n","      results.append(json.loads(res))\n","    end = timer()\n","    elapsed = (end-start)\n","    print(f\"    {f}: E & R took {elapsed}secs\")\n","    return results"]},{"cell_type":"code","execution_count":null,"id":"bb4b86a7","metadata":{"id":"bb4b86a7"},"outputs":[],"source":["%%time\n","failed_files = run_pipeline(200)"]},{"attachments":{},"cell_type":"markdown","id":"653e9c48","metadata":{"id":"653e9c48"},"source":["If processing failed for some files due to API Rate limit or some other error, you can retry as below"]},{"cell_type":"code","execution_count":null,"id":"4e26a851","metadata":{"id":"4e26a851"},"outputs":[],"source":["%%time\n","failed_files = process_pipeline(failed_files)\n","failed_files"]},{"cell_type":"code","execution_count":null,"id":"4d77de32","metadata":{"id":"4d77de32"},"outputs":[],"source":["results"]},{"cell_type":"code","execution_count":null,"id":"12741587","metadata":{"id":"12741587"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"environment":{"kernel":"python3","name":"common-cpu.m108","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cpu:m108"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"toc-autonumbering":true,"toc-showcode":false,"toc-showmarkdowntxt":false,"toc-showtags":false},"nbformat":4,"nbformat_minor":5}
